test sample:
TCGA-A1-A0SE-01Z-00-DX1.04B09232-C6C4-46EF-AA2C-41D078D0A80A.svs
training samples:
TCGA-A2-A0CV-01Z-00-DX1.B02D017A-61CD-45FE-BB31-705CD127DDAB.svs
TCGA-A2-A0CV-01Z-00-DX1.B02D017A-61CD-45FE-BB31-705CD127DDAB.svs
prediction sample:
TCGA-BH-A0B6-01Z-00-DX1.4D982935-F600-4F37-ABB5-13AF74F4FDC4.svs

Epoch = 40

_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 layer_train (Sequential)    (None, 224, 224, 3)       0         
                                                                 
 efficientnetb0 (Functional)  (None, 2)                4052133   
                                                                 
=================================================================
Total params: 4,052,133
Trainable params: 4,010,110
Non-trainable params: 42,023
_________________________________________________________________

Hist.history()

{'loss': [1.186969518661499,
  0.39626771211624146,
  0.35296985507011414,
  0.24561452865600586,
  0.2968408465385437,
  0.21368369460105896,
  0.20202329754829407,
  0.2261997014284134,
  0.19288787245750427,
  0.3029271066188812,
  0.3225507140159607,
  0.20350170135498047,
  0.19333398342132568,
  0.19616472721099854,
  0.18751941621303558,
  0.26242566108703613,
  0.19262807071208954,
  0.18870432674884796,
  0.1801518201828003,
  0.17974239587783813,
  0.18974871933460236,
  0.1778271496295929,
  0.1752403974533081,
  0.16710200905799866,
  0.16850553452968597,
  0.15494099259376526,
  0.15015511214733124,
  0.15166467428207397,
  0.1530962735414505,
  0.13974110782146454,
  0.13562029600143433,
  0.12901990115642548,
  0.12741592526435852,
  0.11818836629390717,
  0.1119154542684555,
  0.1051797866821289,
  0.10201486200094223,
  0.12944604456424713,
  0.08590923994779587,
  0.0779331773519516],
 'accuracy': [0.8255208134651184,
  0.8999255895614624,
  0.9114583134651184,
  0.9140625,
  0.917782723903656,
  0.9192708134651184,
  0.921502947807312,
  0.9140625,
  0.9174107313156128,
  0.9114583134651184,
  0.9211309552192688,
  0.9151785969734192,
  0.9196428656578064,
  0.9129464030265808,
  0.9188988208770752,
  0.921875,
  0.9203869104385376,
  0.9244791865348816,
  0.9304315447807312,
  0.921875,
  0.9159226417541504,
  0.921502947807312,
  0.9229910969734192,
  0.9248511791229248,
  0.9281994104385376,
  0.933407723903656,
  0.9322916865348816,
  0.9348958134651184,
  0.9363839030265808,
  0.9408482313156128,
  0.9501488208770752,
  0.949032723903656,
  0.9475446343421936,
  0.9516369104385376,
  0.9590773582458496,
  0.9590773582458496,
  0.9642857313156128,
  0.9508928656578064,
  0.9717261791229248,
  0.9739583134651184],
 'val_loss': [0.6529862880706787,
  0.7160204648971558,
  0.49677103757858276,
  0.6657902002334595,
  0.6359606981277466,
  0.813144862651825,
  0.5985205173492432,
  0.6959541440010071,
  0.6963246464729309,
  53.776100158691406,
  1.2363322973251343,
  0.6407299637794495,
  0.6779182553291321,
  0.7798304557800293,
  0.8185191750526428,
  1.236725926399231,
  1.1771026849746704,
  0.9701451659202576,
  0.801256537437439,
  0.89857017993927,
  0.9952219128608704,
  0.7848119735717773,
  0.9540924429893494,
  0.8784000873565674,
  0.8985021710395813,
  0.6843187212944031,
  0.7659344673156738,
  1.0986100435256958,
  1.3091974258422852,
  1.2294559478759766,
  1.4190044403076172,
  0.9328277111053467,
  1.0455938577651978,
  1.3809534311294556,
  1.4907588958740234,
  1.3510469198226929,
  1.4393246173858643,
  1.4416110515594482,
  2.2526652812957764,
  1.5145071744918823],
 'val_accuracy': [0.8082386255264282,
  0.8087121248245239,
  0.8077651262283325,
  0.8077651262283325,
  0.8077651262283325,
  0.8077651262283325,
  0.8072916865348816,
  0.8082386255264282,
  0.8091856241226196,
  0.8077651262283325,
  0.8072916865348816,
  0.8082386255264282,
  0.8077651262283325,
  0.8082386255264282,
  0.8077651262283325,
  0.8039772510528564,
  0.8082386255264282,
  0.8058711886405945,
  0.8068181872367859,
  0.8072916865348816,
  0.8068181872367859,
  0.8072916865348816,
  0.8077651262283325,
  0.8087121248245239,
  0.8087121248245239,
  0.814393937587738,
  0.8224431872367859,
  0.8077651262283325,
  0.8058711886405945,
  0.8049242496490479,
  0.8035038113594055,
  0.8480113744735718,
  0.8153409361839294,
  0.8096590638160706,
  0.8068181872367859,
  0.8252840638160706,
  0.8148674368858337,
  0.8101325631141663,
  0.8077651262283325,
  0.8101325631141663]}
model.evaluate(pred_set, batch_size=64

Model.evaluate()
15/15 [==============================] - 4s 234ms/step - loss: 7.2963e-05 - accuracy: 1.0000
[7.296297553693876e-05, 1.0]

Model.predict()
array([[1.0000000e+00, 0.0000000e+00],
       [1.0000000e+00, 0.0000000e+00],
       [1.0000000e+00, 0.0000000e+00],
       ...,
       [1.0000000e+00, 0.0000000e+00],
       [9.9969316e-01, 3.0689751e-04],
       [1.0000000e+00, 0.0000000e+00]], dtype=float32)
