{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for efficientnet on cropped image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import os, sys\n",
    "from time import strftime\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, hamming_loss, roc_curve, auc, f1_score\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL.Image as Image\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import tensorflow as tf #2.8.3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from efficientnet.keras import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader(Sequence):\n",
    "    \"\"\"\n",
    "    Dataset to read image and label for training\n",
    "    \"\"\"\n",
    "    def __init__(self, list_IDs, labels, batch_size=64, dim=(224,224), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.asarray(Image.open(ID))[...,:3]\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 26700\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "    torch.cuda.manual_seed(rand_seed)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using GPU: ', use_gpu)\n",
    "\n",
    "device = torch.device(\"cuda:0\")    \n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = r\"./crops_3/training_pos\" #\"C:\\Users\\emm75\\Documents\\BMI_771\\BMI771_Project\\crops_1\\training_pos\"\n",
    "train_neg = r\"./crops_3/training_neg\" #\"C:\\Users\\emm75\\Documents\\BMI_771\\BMI771_Project\\crops_1\\training_neg\"\n",
    "val_pos = r\"./crops_3/val_pos\" #\"C:\\Users\\emm75\\Documents\\BMI_771\\BMI771_Project\\crops_1\\val_pos\"\n",
    "val_neg = r\"./crops_3/val_neg\" #\"C:\\Users\\emm75\\Documents\\BMI_771\\BMI771_Project\\crops_1\\val_neg\"\n",
    "\n",
    "img_train_pos = [join(train_pos, f) for f in listdir(train_pos) if isfile(join(train_pos, f))]\n",
    "img_train_neg = [join(train_neg, f) for f in listdir(train_neg) if isfile(join(train_neg, f))]\n",
    "img_val_pos = [join(val_pos, f) for f in listdir(val_pos) if isfile(join(val_pos, f))]\n",
    "img_val_neg = [join(val_neg, f) for f in listdir(val_neg) if isfile(join(val_neg, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 2 \n",
    "batch = 64\n",
    "\n",
    "features = {'dim': (224,224),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "label_gen = {}\n",
    "i_pos = img_train_pos + img_val_pos\n",
    "for i in i_pos:\n",
    "    label_gen[i] = 1\n",
    "i_neg = img_train_neg + img_val_neg\n",
    "for j in (i_neg):\n",
    "    label_gen[j] = 0\n",
    "\n",
    "img_gen = {'train': [], 'val': []}\n",
    "g_pos = img_train_pos + img_train_neg\n",
    "for k in g_pos:\n",
    "    img_gen['train'] = img_gen['train'] + [k]\n",
    "g_neg = img_val_pos + img_val_neg\n",
    "for l in (g_neg):\n",
    "    img_gen['test'] = img_gen['test'] + [l]\n",
    "\n",
    "print(img_gen['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_loader(img_gen['train'], label_gen, **features)\n",
    "val_set = data_loader(img_gen['test'], label_gen, **features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_train = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(mode=\"horizontal\"),\n",
    "        layers.RandomFlip(mode=\"vertical\"),\n",
    "    ],\n",
    "    name = 'layer_train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with tf.distribute.MirroredStrategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    trained = layer_train(inputs)\n",
    "    outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(trained)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "\n",
    "hist = model.fit(train_set, epochs=epochs, validation_data=val_set, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos = r\"./crops_1/val_pos\"\n",
    "pred_neg = r\"./crops_1/val_pos\"\n",
    "\n",
    "img_pred_pos = [join(pred_pos, f) for f in listdir(pred_pos) if isfile(join(pred_pos, f))]\n",
    "img_pred_neg = [join(pred_neg, f) for f in listdir(pred_neg) if isfile(join(pred_neg, f))]\n",
    "\n",
    "lab_gen = {}\n",
    "pred_gen = {'predict': []}\n",
    "for i in img_pred_pos:\n",
    "    lab_gen[i] = 1 \n",
    "    pred_gen['predict'] = pred_gen['predict'] + [i]\n",
    "for j in (img_pred_neg):\n",
    "    lab_gen[j] = 0\n",
    "    pred_gen['predict'] = pred_gen['predict'] + [j]\n",
    "\n",
    "pred_set = data_loader(pred_gen['predict'], lab_gen, **features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(pred_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = model.predict(pred_set)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(matrix)\n",
    "np.save(\"large_2_40ep\",matrix)\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c665fadcf6e6fbf1ced26c2f8235cb3705315ce7346e29beb6ac6644407b18c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
